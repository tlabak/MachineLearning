# K Nearest Neighbors and Polynomial Regression
K Nearest Neighbors (KNN) is a supervised learning algorithm used in machine learning for both regression and classification tasks. The KNN algorithm works by finding the K closest data points to a new data point and using the labels or values of these K neighbors to predict the label or value of the new data point. The value of K is chosen based on the problem at hand and can be determined using cross-validation.

KNN is used in a variety of applications such as image recognition, text classification, and anomaly detection. It is popular because it is easy to understand and implement, does not require any training process, and can handle non-linear data.

Polynomial regression is a supervised learning algorithm used for regression tasks in machine learning. The goal of polynomial regression is to find the best-fitting curve that fits the data points. Polynomial regression works by fitting a polynomial equation to the data, where the degree of the polynomial determines the complexity of the model.

Polynomial regression is used in a variety of applications such as predicting housing prices, predicting stock prices, and predicting sales data. It is popular because it can capture non-linear relationships between the input and output variables, and can be used to model complex systems. However, it can also be prone to overfitting if the degree of the polynomial is too high, so careful selection of the degree is important.

## Coding
- Implemented mean squared error loss
- Implemented three distance measures
- Generated polynomial data on which to fit your models 
- Implemented a polynomial regression model
- Implemented a k-nearest neighbor model
